{
  "id": null,
  "uid": "llm-token-cost-economics",
  "title": "ðŸ§  LLM Token & Cost Economics",
  "description": "Track token consumption and estimated costs per model, per node, per task",
  "tags": [
    "agent",
    "cost",
    "tokens",
    "llm",
    "p0"
  ],
  "timezone": "browser",
  "schemaVersion": 39,
  "version": 1,
  "refresh": "30s",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "links": [],
  "panels": [
    {
      "id": 1,
      "title": "Total Tokens (24h)",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 0,
        "y": 0
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum(increase(llm_tokens_total[24h])) or vector(0)",
          "legendFormat": "Tokens",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "area",
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "value",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "color": {
            "mode": "fixed",
            "fixedColor": "blue"
          }
        }
      }
    },
    {
      "id": 2,
      "title": "Estimated Cost (24h)",
      "description": "Based on: gpt-4o ($5/1M input, $15/1M output), gpt-4o-mini ($0.15/1M input, $0.60/1M output)",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 6,
        "y": 0
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "(sum(increase(llm_tokens_total{model=\"gpt-4o\", type=\"prompt\"}[24h])) * 5 / 1000000 + sum(increase(llm_tokens_total{model=\"gpt-4o\", type=\"completion\"}[24h])) * 15 / 1000000 + sum(increase(llm_tokens_total{model=\"gpt-4o-mini\", type=\"prompt\"}[24h])) * 0.15 / 1000000 + sum(increase(llm_tokens_total{model=\"gpt-4o-mini\", type=\"completion\"}[24h])) * 0.6 / 1000000) or vector(0)",
          "legendFormat": "Cost",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "area",
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "value",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "currencyUSD",
          "decimals": 4,
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "green"
              },
              {
                "value": 10,
                "color": "yellow"
              },
              {
                "value": 50,
                "color": "red"
              }
            ]
          }
        }
      }
    },
    {
      "id": 3,
      "title": "Prompt Tokens (24h)",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 12,
        "y": 0
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum(increase(llm_tokens_total{type=\"prompt\"}[24h])) or vector(0)",
          "legendFormat": "Prompt",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "area",
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "value",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "color": {
            "mode": "fixed",
            "fixedColor": "orange"
          }
        }
      }
    },
    {
      "id": 4,
      "title": "Completion Tokens (24h)",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 18,
        "y": 0
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum(increase(llm_tokens_total{type=\"completion\"}[24h])) or vector(0)",
          "legendFormat": "Completion",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "area",
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "value",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "color": {
            "mode": "fixed",
            "fixedColor": "purple"
          }
        }
      }
    },
    {
      "id": 5,
      "title": "Token Usage by Model",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 6
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum by(model) (rate(llm_tokens_total[5m]))",
          "legendFormat": "{{model}}",
          "refId": "A"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "lineWidth": 2,
            "fillOpacity": 20,
            "stacking": {
              "mode": "normal",
              "group": "A"
            }
          }
        }
      }
    },
    {
      "id": 6,
      "title": "Token Usage by Node",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 6
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum by(node) (rate(llm_tokens_total[5m]))",
          "legendFormat": "{{node}}",
          "refId": "A"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "lineWidth": 2,
            "fillOpacity": 20,
            "stacking": {
              "mode": "normal",
              "group": "A"
            }
          }
        }
      }
    },
    {
      "id": 7,
      "title": "Model Cost Breakdown (24h)",
      "type": "piechart",
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 0,
        "y": 14
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum(increase(llm_tokens_total{model=\"gpt-4o\", type=\"prompt\"}[24h])) * 5 / 1000000 + sum(increase(llm_tokens_total{model=\"gpt-4o\", type=\"completion\"}[24h])) * 15 / 1000000 or vector(0)",
          "legendFormat": "gpt-4o",
          "refId": "A"
        },
        {
          "expr": "sum(increase(llm_tokens_total{model=\"gpt-4o-mini\", type=\"prompt\"}[24h])) * 0.15 / 1000000 + sum(increase(llm_tokens_total{model=\"gpt-4o-mini\", type=\"completion\"}[24h])) * 0.6 / 1000000 or vector(0)",
          "legendFormat": "gpt-4o-mini",
          "refId": "B"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "table",
          "placement": "right",
          "values": [
            "value",
            "percent"
          ]
        },
        "pieType": "donut",
        "tooltip": {
          "mode": "single"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "currencyUSD",
          "decimals": 4
        }
      }
    },
    {
      "id": 8,
      "title": "Cost Over Time",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 16,
        "x": 8,
        "y": 14
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "(sum(rate(llm_tokens_total{model=\"gpt-4o\", type=\"prompt\"}[5m])) * 5 / 1000000 + sum(rate(llm_tokens_total{model=\"gpt-4o\", type=\"completion\"}[5m])) * 15 / 1000000) * 60 or vector(0)",
          "legendFormat": "gpt-4o $/min",
          "refId": "A"
        },
        {
          "expr": "(sum(rate(llm_tokens_total{model=\"gpt-4o-mini\", type=\"prompt\"}[5m])) * 0.15 / 1000000 + sum(rate(llm_tokens_total{model=\"gpt-4o-mini\", type=\"completion\"}[5m])) * 0.6 / 1000000) * 60 or vector(0)",
          "legendFormat": "gpt-4o-mini $/min",
          "refId": "B"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "currencyUSD",
          "custom": {
            "lineWidth": 2,
            "fillOpacity": 10
          }
        }
      }
    },
    {
      "id": 9,
      "title": "Avg Tokens per LLM Call",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 6,
        "x": 0,
        "y": 22
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum(rate(llm_tokens_total[5m])) / sum(rate(llm_calls_total[5m])) or vector(0)",
          "legendFormat": "Avg",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "area",
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "value",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0
        }
      }
    },
    {
      "id": 10,
      "title": "LLM Latency (P50/P95/P99)",
      "type": "timeseries",
      "gridPos": {
        "h": 6,
        "w": 18,
        "x": 6,
        "y": 22
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(llm_request_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P50",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(llm_request_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P95",
          "refId": "B"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(llm_request_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P99",
          "refId": "C"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "custom": {
            "lineWidth": 2,
            "fillOpacity": 5
          }
        }
      }
    },
    {
      "id": 11,
      "title": "Projected Monthly Cost",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 8,
        "x": 0,
        "y": 28
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "((sum(rate(llm_tokens_total{model=\"gpt-4o\", type=\"prompt\"}[1h])) * 5 / 1000000 + sum(rate(llm_tokens_total{model=\"gpt-4o\", type=\"completion\"}[1h])) * 15 / 1000000 + sum(rate(llm_tokens_total{model=\"gpt-4o-mini\", type=\"prompt\"}[1h])) * 0.15 / 1000000 + sum(rate(llm_tokens_total{model=\"gpt-4o-mini\", type=\"completion\"}[1h])) * 0.6 / 1000000) * 3600 * 24 * 30) or vector(0)",
          "legendFormat": "Monthly",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "none",
        "orientation": "auto",
        "textMode": "value_and_name",
        "colorMode": "value",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "currencyUSD",
          "decimals": 2,
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "value": null,
                "color": "green"
              },
              {
                "value": 100,
                "color": "yellow"
              },
              {
                "value": 500,
                "color": "red"
              }
            ]
          }
        }
      }
    },
    {
      "id": 12,
      "title": "Cost Savings (gpt-4o-mini vs gpt-4o)",
      "description": "Estimated savings by using gpt-4o-mini for extraction instead of gpt-4o",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 8,
        "x": 8,
        "y": 28
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "((sum(increase(llm_tokens_total{model=\"gpt-4o-mini\", type=\"prompt\"}[24h])) * (5 - 0.15) / 1000000 + sum(increase(llm_tokens_total{model=\"gpt-4o-mini\", type=\"completion\"}[24h])) * (15 - 0.6) / 1000000)) or vector(0)",
          "legendFormat": "Saved",
          "refId": "A"
        }
      ],
      "options": {
        "graphMode": "area",
        "orientation": "auto",
        "textMode": "value_and_name",
        "colorMode": "background",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ]
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "currencyUSD",
          "decimals": 4,
          "color": {
            "mode": "fixed",
            "fixedColor": "green"
          }
        }
      }
    },
    {
      "id": 13,
      "title": "LLM Calls by Model",
      "type": "timeseries",
      "gridPos": {
        "h": 6,
        "w": 8,
        "x": 16,
        "y": 28
      },
      "datasource": {
        "type": "prometheus",
        "uid": "${datasource}"
      },
      "targets": [
        {
          "expr": "sum by(model) (rate(llm_calls_total[5m]))",
          "legendFormat": "{{model}}",
          "refId": "A"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "custom": {
            "lineWidth": 2,
            "fillOpacity": 10
          }
        }
      }
    }
  ],
  "templating": {
    "list": [
      {
        "name": "datasource",
        "type": "datasource",
        "query": "prometheus",
        "current": {},
        "hide": 0,
        "includeAll": false,
        "multi": false,
        "options": [],
        "refresh": 1,
        "regex": ""
      }
    ]
  },
  "time": {
    "from": "now-24h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": [
      "5s",
      "10s",
      "30s",
      "1m",
      "5m",
      "15m",
      "30m",
      "1h",
      "2h",
      "1d"
    ]
  },
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  }
}
